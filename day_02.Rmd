---
title: "Intro to Bayesian (Linear Models) for Speech and Language Scientists"
subtitle: "Day 2"
output: 
  html_document: 
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, out.height = "400px", dpi = 300,
  fig.align = "center", fig.width = 7, fig.height = 5
)
knitr::opts_knit$set(root.dir = here::here())

library(tidyverse)
theme_set(theme_light())

library(lme4)
library(ggeffects)
library(brms)
library(cmdstanr)
library(tidybayes)
library(bayesplot)
```

# Read the data

```{r mald}
mald <- readRDS("./data/mald.rds")
```

[Massive Auditory Lexical Decision](https://aphl.artsrn.ualberta.ca/?page_id=827) (Tucker et al. 2019):

- **MALD data set**: 521 subjects, RTs and accuracy.

- Subset of MALD: 30 subjects, 100 observations each.

```{r mald-print}
mald
```

# The empirical rule

```{r empirical-rule-5, echo=FALSE}
x <- seq(-4, 4, by = 0.01)
y = dnorm(x, 0, 1)
ggplot() +
  aes(x, y) +
  geom_ribbon(aes(x = x, ymin = 0, ymax = y), alpha = 0.3, fill = "#8970FF") +
  geom_ribbon(aes(x = ifelse(x >= -2 & x <= 2, x, NA), ymin = 0, ymax = y), alpha = 0.4, fill = "#8970FF") +
  geom_ribbon(aes(x = ifelse(x >= -1 & x <= 1, x, NA), ymin = 0, ymax = y), alpha = 0.7, fill = "#8970FF") +
  geom_line(size = 2, colour = "#FFA70B") +
  annotate(
    "segment",
    x = -1, xend = 1, y = 0.45, yend = 0.45,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    size = 1
  ) +
  annotate("label", x = 0, y = 0.45, label = "68%") +
  annotate(
    "segment",
    x = -2, xend = 2, y = 0.5, yend = 0.5,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    size = 1
  ) +
  annotate("label", x = 0, y = 0.50, label = "95%") +
  annotate(
    "segment",
    x = -3, xend = 3, y = 0.55, yend = 0.55,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    size = 1
  ) +
  annotate("label", x = 0, y = 0.55, label = "99.7 â‰ˆ 100%") +
  scale_x_continuous(breaks = c(-4:4), labels = c("", expression(paste(-3, sigma)), expression(paste(-2, sigma)), expression(paste(-1, sigma)), expression(paste(mu)), expression(paste(+1, sigma)), expression(paste(+2, sigma)), expression(paste(+3, sigma)), "")) +
  ylim(0, 0.6) +
  labs(
    x = element_blank(), y = element_blank()
  )
```

As a general rule, $\pm2\sigma$ covers 95% of the Gaussian distribution, which means we are 95% confident that the value lies within that range.

# Example 1: Reaction Times

Fill this form: <https://forms.gle/M7juHsxyv5Vbs7Gx7>.

## Seeing is believing

```{r mu1-prior, echo=FALSE}
x <- seq(-6000, 6000)
ggplot() +
  aes(x = x, y = dnorm(x, 0, 1500)) +
  geom_line(size = 2, colour = "#8970FF") +
  labs(
    x = "Mean RT (ms)", y = "Density",
    title = expression(paste("Prior for ", mu)),
    subtitle = expression(paste(mu[1], "=0", ", ", sigma[1], "=1500"))
  )
```

## Get the default priors

```{r get-prior}
get_prior(
  RT ~ 1,
  data = mald,
  family = gaussian
)
```

## Prior for $\sigma$: Half Cauchy

```{r cauchy, echo=FALSE}
x <- seq(0, 1500, by = 0.1)
y <- dhcauchy(x, sigma = 100)
ggplot() +
  aes(x, y) +
  geom_line(size = 2) +
  labs(
    x = "RT standard deviation (ms)", y = "Density",
    title = "Half Cauchy distribution",
    subtitle = expression(paste(mu, "=0", ", ", sigma, "=100"))
  )
```

```{r hdi-hcauchy}
HDInterval::inverseCDF(
  c(0.5, 0.75, 0.95),
  phcauchy,
  sigma = 50
)

HDInterval::inverseCDF(
  c(0.5, 0.75, 0.95),
  phcauchy,
  sigma = 100
)
```

## Prior Predictive Checks

```{r rt-1-pp}
my_priors <- c(
  prior(normal(0, 1500), class = Intercept), # Intercept (i.e. mu)
  prior(cauchy(0, 100), class = sigma)  # sigma
)

rt_1_pp <- brm(
  RT ~ 1,
  data = mald,
  family = gaussian,
  prior = my_priors,
  sample_prior = "only",
  cores = my_cores,
  file = "./data/rt_1_pp",
  backend = "cmdstanr"
)
```

```{r rt-1-pp-plot, echo=FALSE, warning=FALSE}
rt_1_pp_d <- rt_1_pp %>%
  spread_draws(b_Intercept, sigma) %>%
  slice_sample(n = 100)

rt_1_pp_d %>%
  mutate(
    x = map2(b_Intercept, sigma, ~rnorm(1000, .x, .y)),
  ) %>%
  unnest(cols = x) %>%
  ggplot(aes(x)) +
  geom_density(size = 2, adjust = 10) +
  geom_rug(alpha = 0.2) +
  theme(legend.position = "none") +
  labs(
    x = "RT (ms)", y = "Density",
    title = "Expected distribution of RTs"
  ) +
  xlim(-1e4, +1e4)
```

## Run the model

```{r rt-1}
my_priors <- c(
  prior(normal(0, 1500), class = Intercept), # Intercept (i.e. mu)
  prior(cauchy(0, 100), class = sigma)  # sigma
)

rt_1 <- brm(
  RT ~ 1,
  data = mald,
  family = gaussian,
  prior = my_priors,
  cores = my_cores,
  file = "./data/rt_1",
  backend = "cmdstanr"
)
```

```{r rt-1-sum}
rt_1
```

## Posterior Predictive Checks

```{r rt-1-ppc, echo=FALSE}
pp_check(rt_1, ndraws = 50)
```

# BREAK

Time for a break!

# PP check didn't look good...

```{r rt-1-ppc-2, echo=FALSE}
pp_check(rt_1, ndraws = 50)
```


# Example 2: Accuracy

```{r mald-print-2}
mald
```

```{r acc-pd, echo=FALSE}
mald %>%
  ggplot(aes(ACC, PhonLev, colour = ACC)) +
  geom_jitter(alpha = 0.7, width = 0.2)
```

```{r acc-pd-2, echo=FALSE}
mald %>%
  ggplot(aes(PhonLev, fill = ACC)) +
  geom_density(alpha = 0.35) +
  geom_rug(alpha = 0.2)
```

```{r acc-pd-3, echo=FALSE}
mald %>%
  ggplot(aes(PhonLev, fill = ACC)) +
  geom_histogram(alpha = 0.9, bins = 50) +
  facet_grid(ACC ~ .)
```


## Log-odds and probabilities

```{r p-log-odds, echo=FALSE}
dots <- tibble(
  p = seq(0.1, 0.9, by = 0.1),
  log_odds = qlogis(p)
)
tibble(
  p = seq(0, 1, by = 0.001),
  log_odds = qlogis(p)
) %>%
  ggplot(aes(log_odds, p)) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  geom_hline(yintercept = 0, colour = "#8856a7", size = 1) +
  geom_hline(yintercept = 1, colour = "#8856a7", size = 1) +
  geom_vline(xintercept = 0, alpha = 0.5) +
  geom_line(size = 2) +
  geom_point(data = dots, size = 4) +
  scale_x_continuous(breaks = seq(-6, 6, by = 1), minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  labs(
    title = "Correspondence between log-odds and probabilities",
    x = "log-odds",
    y = "probability"
  )
```

## Run the model

```{r acc-1}
priors <- c(
  prior(normal(0, 1.5), class = Intercept), # beta_0
  prior(normal(0, 1), class = b, coef = PhonLev) # beta_1
)

acc_1 <- brm(
  ACC ~ PhonLev,
  data = mald,
  family = bernoulli,
  prior = priors,
  cores = my_cores,
  file = "./data/acc_1",
  backend = "cmdstanr"
)
```

```{r acc-1-cond}
conditional_effects(acc_1, "PhonLev")
```

```{r acc-2}
priors <- c(
  prior(normal(0, 1.5), class = Intercept), # beta_0
  prior(normal(0, 1), class = b, coef = PhonLev), # beta_1
  prior(normal(0, 1), class = b, coef = IsWordFALSE), # beta_2
  prior(normal(0, 1), class = b, coef = `PhonLev:IsWordFALSE`) # beta_3
)

acc_2 <- brm(
  ACC ~ PhonLev * IsWord,
  data = mald,
  family = bernoulli,
  prior = priors,
  cores = my_cores,
  file = "./data/acc_2",
  backend = "cmdstanr"
)
```


```{r acc-2-cond}
conditional_effects(acc_2, "PhonLev:IsWord")
```

